{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import random\n",
    "import tarfile\n",
    "import tempfile\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd() / \"data\"\n",
    "\n",
    "train_path = data_dir / \"annotations/train.jsonl\"\n",
    "dev_path = data_dir / \"annotations/dev_seen.jsonl\"\n",
    "test_path = data_dir / \"annotations/test_seen.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42953</td>\n",
       "      <td>img/42953.png</td>\n",
       "      <td>0</td>\n",
       "      <td>its their character not their color that matters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23058</td>\n",
       "      <td>img/23058.png</td>\n",
       "      <td>0</td>\n",
       "      <td>don't be afraid to love again everyone is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13894</td>\n",
       "      <td>img/13894.png</td>\n",
       "      <td>0</td>\n",
       "      <td>putting bows on your pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37408</td>\n",
       "      <td>img/37408.png</td>\n",
       "      <td>0</td>\n",
       "      <td>i love everything and everybody! except for sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82403</td>\n",
       "      <td>img/82403.png</td>\n",
       "      <td>0</td>\n",
       "      <td>everybody loves chocolate chip cookies, even h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            img  label  \\\n",
       "0  42953  img/42953.png      0   \n",
       "1  23058  img/23058.png      0   \n",
       "2  13894  img/13894.png      0   \n",
       "3  37408  img/37408.png      0   \n",
       "4  82403  img/82403.png      0   \n",
       "\n",
       "                                                text  \n",
       "0   its their character not their color that matters  \n",
       "1  don't be afraid to love again everyone is not ...  \n",
       "2                           putting bows on your pet  \n",
       "3  i love everything and everybody! except for sq...  \n",
       "4  everybody loves chocolate chip cookies, even h...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples_frame = pd.read_json(train_path, lines=True)\n",
    "train_samples_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5481\n",
       "1    3019\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples_frame.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8500.000000\n",
       "mean       11.748706\n",
       "std         6.877880\n",
       "min         1.000000\n",
       "25%         7.000000\n",
       "50%        10.000000\n",
       "75%        15.000000\n",
       "max        70.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples_frame.text.map(\n",
    "    lambda text: len(text.split(\" \"))\n",
    ").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HatefulMemesDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Uses jsonl data to preprocess and serve \n",
    "    dictionary of multimodal tensors for model input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path,\n",
    "        img_dir,\n",
    "        image_transform,\n",
    "        text_transform,\n",
    "        balance=False,\n",
    "        dev_limit=None,\n",
    "        random_state=0,\n",
    "    ):\n",
    "\n",
    "        self.samples_frame = pd.read_json(\n",
    "            data_path, lines=True\n",
    "        )\n",
    "        self.dev_limit = dev_limit\n",
    "        if balance:\n",
    "            neg = self.samples_frame[\n",
    "                self.samples_frame.label.eq(0)\n",
    "            ]\n",
    "            pos = self.samples_frame[\n",
    "                self.samples_frame.label.eq(1)\n",
    "            ]\n",
    "            self.samples_frame = pd.concat(\n",
    "                [\n",
    "                    neg.sample(\n",
    "                        pos.shape[0], \n",
    "                        random_state=random_state\n",
    "                    ), \n",
    "                    pos\n",
    "                ]\n",
    "            )\n",
    "        if self.dev_limit:\n",
    "            if self.samples_frame.shape[0] > self.dev_limit:\n",
    "                self.samples_frame = self.samples_frame.sample(\n",
    "                    dev_limit, random_state=random_state\n",
    "                )\n",
    "        self.samples_frame = self.samples_frame.reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        self.samples_frame.img = self.samples_frame.apply(\n",
    "            lambda row: (img_dir / row.img), axis=1\n",
    "        )\n",
    "\n",
    "        # https://github.com/drivendataorg/pandas-path\n",
    "        if not self.samples_frame.img.path.exists().all():\n",
    "            raise FileNotFoundError\n",
    "        if not self.samples_frame.img.path.is_file().all():\n",
    "            raise TypeError\n",
    "            \n",
    "        self.image_transform = image_transform\n",
    "        self.text_transform = text_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"This method is called when you do len(instance) \n",
    "        for an instance of this class.\n",
    "        \"\"\"\n",
    "        return len(self.samples_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"This method is called when you do instance[key] \n",
    "        for an instance of this class.\n",
    "        \"\"\"\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_id = self.samples_frame.loc[idx, \"id\"]\n",
    "\n",
    "        image = Image.open(\n",
    "            self.samples_frame.loc[idx, \"img\"]\n",
    "        ).convert(\"RGB\")\n",
    "        image = self.image_transform(image)\n",
    "\n",
    "        text = torch.Tensor(\n",
    "            self.text_transform.get_sentence_vector(\n",
    "                self.samples_frame.loc[idx, \"text\"]\n",
    "            )\n",
    "        ).squeeze()\n",
    "\n",
    "        if \"label\" in self.samples_frame.columns:\n",
    "            label = torch.Tensor(\n",
    "                [self.samples_frame.loc[idx, \"label\"]]\n",
    "            ).long().squeeze()\n",
    "            sample = {\n",
    "                \"id\": img_id, \n",
    "                \"image\": image, \n",
    "                \"text\": text, \n",
    "                \"label\": label\n",
    "            }\n",
    "        else:\n",
    "            sample = {\n",
    "                \"id\": img_id, \n",
    "                \"image\": image, \n",
    "                \"text\": text\n",
    "            }\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
